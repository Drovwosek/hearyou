#!/usr/bin/env python3
"""
HearYou STT Service - FastAPI –≤–µ–±-—Å–µ—Ä–≤–∏—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Header, Request
from fastapi.responses import StreamingResponse, HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.exceptions import RequestValidationError
from pydantic import ValidationError
import uvicorn
import asyncio
import os
import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Optional, List
import hashlib
import shutil
import re
import logging
import traceback as tb

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç –∏–∑ –æ–±—â–µ–≥–æ –º–æ–¥—É–ª—è core
sys.path.insert(0, '/root/hearyou')

from core.yandex_stt import YandexSTT
from core.text_cleaner import TranscriptionCleaner

# JTBD –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (—Ç—Ä–µ–±—É–µ—Ç anthropic)
try:
    from core.jtbd_analyzer import JTBDAnalyzer
    JTBD_AVAILABLE = True
except ImportError:
    JTBD_AVAILABLE = False
    logger.warning("JTBD Analyzer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç 'anthropic'")

from ispring_hints import DEFAULT_HINTS
from speaker_diarization_resemblyzer import (
    SpeakerDiarizationResemblyzer,
    merge_transcription_with_speakers,
    format_with_speakers as format_speakers_dialogue
)

app = FastAPI(
    title="HearYou STT Service",
    description="–°–µ—Ä–≤–∏—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Yandex SpeechKit",
    version="1.0.0"
)

# Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    
    # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥—è—â–∏–π –∑–∞–ø—Ä–æ—Å (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ)
    logger.info(f"{request.method} {request.url.path} from {request.client.host if request.client else 'unknown'}")
    
    # –î–ª—è POST /transcribe –ª–æ–≥–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
    if request.method == "POST" and request.url.path == "/transcribe":
        logger.info(f"üîç Content-Type: {request.headers.get('content-type')}")
        logger.info(f"üîç Content-Length: {request.headers.get('content-length')}")
        # –ù–ï —á–∏—Ç–∞–µ–º body –≤ middleware - —ç—Ç–æ –ª–æ–º–∞–µ—Ç multipart/form-data –ø–∞—Ä—Å–∏–Ω–≥ –≤ FastAPI!
    
    try:
        response = await call_next(request)
        duration = time.time() - start_time
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        logger.info(f"{request.method} {request.url.path} -> {response.status_code} ({duration:.2f}s)")
        
        # –ï—Å–ª–∏ 400 –Ω–∞ /transcribe - –ª–æ–≥–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ + response body
        if response.status_code >= 400 and request.url.path == "/transcribe":
            logger.error(f"‚ùå HTTP {response.status_code} on /transcribe")
            logger.error(f"‚ùå Request took {duration:.2f}s")
            
            # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å response body –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            if hasattr(response, 'body'):
                try:
                    body = response.body.decode('utf-8')[:500]  # –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤
                    logger.error(f"‚ùå Response body: {body}")
                except Exception as e:
                    logger.error(f"‚ùå Could not read response body: {e}")
            
            logger.error(f"‚ùå This suggests FastAPI rejected the request before reaching the endpoint")
            logger.error(f"‚ùå Possible causes: invalid Content-Type, missing required fields, or parsing error")
        
        return response
    except Exception as e:
        logger.error(f"{request.method} {request.url.path} failed: {e}")
        logger.error(tb.format_exc())
        raise

# CORS –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Exception handlers –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.error(f"‚ùå VALIDATION ERROR on {request.method} {request.url.path}")
    logger.error(f"‚ùå Client: {request.client.host if request.client else 'unknown'}")
    logger.error(f"‚ùå Content-Type: {request.headers.get('content-type')}")
    logger.error(f"‚ùå Errors count: {len(exc.errors())}")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ –∫–∞–∂–¥–æ–π –æ—à–∏–±–∫–∏
    for i, error in enumerate(exc.errors(), 1):
        loc = ' -> '.join(str(x) for x in error.get('loc', []))
        logger.error(f"  ‚ùå Error {i}:")
        logger.error(f"     Location: {loc}")
        logger.error(f"     Type: {error.get('type')}")
        logger.error(f"     Message: {error.get('msg')}")
        if 'input' in error:
            input_str = str(error.get('input'))[:100]  # –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤
            logger.error(f"     Input: {input_str}")
    
    return JSONResponse(
        status_code=422,
        content={
            "detail": exc.errors(),
            "message": "Validation failed - check server logs for details"
        }
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    logger.error(f"‚ùå HTTP Exception {exc.status_code} on {request.method} {request.url.path}")
    logger.error(f"‚ùå Detail: {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"‚ùå Unhandled exception on {request.method} {request.url.path}: {type(exc).__name__}")
    logger.error(f"‚ùå Message: {str(exc)}")
    logger.error(f"‚ùå Traceback:")
    logger.error(tb.format_exc())
    
    return JSONResponse(
        status_code=500,
        content={"detail": f"Internal server error: {str(exc)}"}
    )

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
UPLOAD_DIR = Path("uploads")
RESULTS_DIR = Path("results")
TEMP_DIR = Path("temp")

UPLOAD_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)
TEMP_DIR.mkdir(exist_ok=True)

# –õ–æ–≥–∏
LOGS_DIR = Path("/app/logs")
LOGS_DIR.mkdir(exist_ok=True)

# –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è chunked uploads
CHUNKS_DIR = Path("/app/chunks")
CHUNKS_DIR.mkdir(exist_ok=True)

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (25 –ì–ë - –¥–ª—è –≤–∏–¥–µ–æ, –∞—É–¥–∏–æ —ç–∫—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
MAX_FILE_SIZE = 25 * 1024 * 1024 * 1024

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ chunked uploads
chunked_uploads = {}  # {upload_id: {filename, total_chunks, received_chunks, file_path}}

# Whitelist —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
# –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–∞ - –ø—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±—ã–µ —Ñ–∞–π–ª—ã —Å –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–æ–º (–ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ ffprobe)
# –ú–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å whitelist –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç—ã:
# ALLOWED_EXTENSIONS = {'.mp3', '.wav', '.aac', '.m4a', '.ogg', '.opus', '.flac', ...}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è STT (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π S3 –¥–ª—è async API)
stt = YandexSTT(
    s3_access_key=os.getenv('YANDEX_S3_ACCESS_KEY'),
    s3_secret_key=os.getenv('YANDEX_S3_SECRET_KEY'),
    s3_bucket=os.getenv('YANDEX_S3_BUCKET', 'hearyou-stt-temp')
)
cleaner = TranscriptionCleaner()  # –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ—á–∏—Å—Ç–∫–∏ (–∑–≤—É–∫–∏ + –ø–∞—Ä–∞–∑–∏—Ç—ã + –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)
diarizer = SpeakerDiarizationResemblyzer()  # Speaker diarization —á–µ—Ä–µ–∑ Resemblyzer

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è JTBD –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (—Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –µ—Å–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–∞)
if JTBD_AVAILABLE:
    try:
        jtbd_analyzer = JTBDAnalyzer()
        logger.info("JTBD Analyzer initialized successfully")
    except ValueError as e:
        logger.warning(f"JTBD Analyzer not initialized: {e}")
        jtbd_analyzer = None
else:
    jtbd_analyzer = None
    logger.info("JTBD Analyzer disabled (anthropic package not installed)")


def format_with_speakers(result_data: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
    
    Args:
        result_data: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç Yandex API —Å speakerLabeling
        
    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
    """
    chunks = result_data.get('chunks', [])
    
    if not chunks:
        # –ï—Å–ª–∏ –Ω–µ—Ç chunks, –≤–µ—Ä–Ω—É—Ç—å –æ–±—ã—á–Ω—ã–π result
        return result_data.get('result', '')
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    all_words = []
    
    for chunk in chunks:
        for alt in chunk.get('alternatives', []):
            for word_data in alt.get('words', []):
                speaker_tag = word_data.get('speakerTag')
                if speaker_tag is not None:  # –ï—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ø–∏–∫–µ—Ä–µ
                    word = word_data.get('word', '')
                    start_time = word_data.get('startTime', '0s')
                    all_words.append({
                        'word': word,
                        'speaker': speaker_tag,
                        'time': start_time
                    })
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–ø–∏–∫–µ—Ä–∞—Ö, –≤–µ—Ä–Ω—É—Ç—å –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    if not all_words:
        return result_data.get('result', '')
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤
    unique_speakers = set(w['speaker'] for w in all_words)
    if len(unique_speakers) <= 1:
        # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–ø–∏–∫–µ—Ä - –≤–µ—Ä–Ω—É—Ç—å –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
        return result_data.get('result', '')
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º (–¥–∏–∞–ª–æ–≥)
    dialog = []
    current_speaker = None
    current_text = []
    
    for word_info in all_words:
        speaker = word_info['speaker']
        word = word_info['word']
        
        if speaker != current_speaker:
            # –°–º–µ–Ω–∏–ª—Å—è —Å–ø–∏–∫–µ—Ä - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â—É—é —Ä–µ–ø–ª–∏–∫—É
            if current_speaker is not None and current_text:
                text = ' '.join(current_text)
                dialog.append(f"–°–ø–∏–∫–µ—Ä {current_speaker}: {text}")
            
            # –ù–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Ä–µ–ø–ª–∏–∫—É
            current_speaker = speaker
            current_text = [word]
        else:
            # –¢–æ—Ç –∂–µ —Å–ø–∏–∫–µ—Ä - –¥–æ–±–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ
            current_text.append(word)
    
    # –î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–ø–ª–∏–∫—É
    if current_speaker is not None and current_text:
        text = ' '.join(current_text)
        dialog.append(f"–°–ø–∏–∫–µ—Ä {current_speaker}: {text}")
    
    return '\n\n'.join(dialog)


# –û—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á
task_queue = asyncio.Queue()
tasks_status = {}  # {task_id: {status, progress, result}}

# Rate limiting (–ø—Ä–æ—Å—Ç–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ø–∞–º–∞)
from collections import defaultdict
import time

request_counts = defaultdict(list)  # {ip: [timestamp1, timestamp2, ...]}
RATE_LIMIT_WINDOW = 60  # 60 —Å–µ–∫—É–Ω–¥
RATE_LIMIT_MAX_REQUESTS = 10  # –ú–∞–∫—Å–∏–º—É–º 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É

# –ü—Ä–æ—Å—Ç–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
VALID_TOKENS = {
    "artem_token": "Artem",
    "test_token": "Test User",
}

def verify_token(authorization: Optional[str] = Header(None)) -> str:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"""
    if not authorization:
        # –í dev —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–µ—à–∞–µ–º –±–µ–∑ —Ç–æ–∫–µ–Ω–∞
        return "anonymous"
    
    token = authorization.replace("Bearer ", "")
    if token in VALID_TOKENS:
        return VALID_TOKENS[token]
    
    raise HTTPException(status_code=401, detail="Invalid token")


def check_rate_limit(client_ip: str) -> None:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ rate limit –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç —Å–ø–∞–º–∞
    –ú–∞–∫—Å–∏–º—É–º 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É —Å –æ–¥–Ω–æ–≥–æ IP
    """
    now = time.time()
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
    request_counts[client_ip] = [
        ts for ts in request_counts[client_ip] 
        if now - ts < RATE_LIMIT_WINDOW
    ]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞
    if len(request_counts[client_ip]) >= RATE_LIMIT_MAX_REQUESTS:
        raise HTTPException(
            status_code=429,
            detail=f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ú–∞–∫—Å–∏–º—É–º {RATE_LIMIT_MAX_REQUESTS} –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É."
        )
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    request_counts[client_ip].append(now)


def sanitize_filename(filename: str) -> str:
    """
    –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –∏–Ω—ä–µ–∫—Ü–∏–π
    - –£–¥–∞–ª—è–µ—Ç –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    - –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–ª–∏–Ω—É
    - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    - –ù–ò–ö–û–ì–î–ê –Ω–µ –ø–∞–¥–∞–µ—Ç ‚Äî –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–ª–∏–¥–Ω–æ–µ –∏–º—è
    """
    try:
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞ (–±–µ–∑ –ø—É—Ç–∏)
        filename = str(filename)  # –Ø–≤–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Å—Ç—Ä–æ–∫–µ
        filename = Path(filename).name
        
        # –£–¥–∞–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ –±–∞–π—Ç—ã
        filename = filename.replace('\x00', '')
        
        # –ï—Å–ª–∏ –ø—É—Å—Ç–æ–µ –∏–º—è –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        if not filename or filename.strip() == '':
            return 'file.mp3'
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∏–º—è –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
        parts = filename.rsplit('.', 1)
        
        if len(parts) == 2:
            name, extension = parts[0], parts[1]
            ext = '.' + extension.lower() if extension else '.mp3'
        else:
            name = parts[0]
            ext = '.mp3'  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã:
        # –±—É–∫–≤—ã (–ª–∞—Ç–∏–Ω–∏—Ü–∞ + –∫–∏—Ä–∏–ª–ª–∏—Ü–∞), —Ü–∏—Ñ—Ä—ã, –¥–µ—Ñ–∏—Å, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ, –ø—Ä–æ–±–µ–ª—ã
        name = re.sub(r'[^\w\s\-–∞-—è–ê-–Ø—ë–Å]', '_', name, flags=re.UNICODE)
        
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è
        name = re.sub(r'[\s_]+', '_', name)
        
        # –£–±–∏—Ä–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ/–∫–æ–Ω–µ—á–Ω—ã–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        name = name.strip('_-. ')
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É (–º–∞–∫—Å 200 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(name) > 200:
            name = name[:200]
        
        # –ï—Å–ª–∏ –∏–º—è —Å—Ç–∞–ª–æ –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        if not name or name == '':
            name = 'file'
        
        result = name + ext
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
        if not result or result == '' or result == '.':
            return 'file.mp3'
        
        return result
        
    except Exception as e:
        # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è
        logger.warning(f"Filename sanitization exception: {e}, using fallback")
        return 'file.mp3'


def sanitize_language_code(lang: str) -> str:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è —è–∑—ã–∫–æ–≤–æ–≥–æ –∫–æ–¥–∞
    –†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–¥—ã –≤–∏–¥–∞: xx-XX
    """
    # Whitelist —è–∑—ã–∫–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö Yandex
    allowed_languages = {
        'ru-RU', 'en-US', 'tr-TR', 'uk-UK', 'uz-UZ', 
        'kk-KK', 'de-DE', 'fr-FR', 'es-ES'
    }
    
    if lang in allowed_languages:
        return lang
    
    # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º ru-RU –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    return 'ru-RU'


def validate_file_security(filename: str, file_path: Path) -> None:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    import subprocess
    
    # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: ffprobe –≤–∞–ª–∏–¥–∞—Ü–∏—è (–ø—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–æ–º)
    try:
        result = subprocess.run([
            'ffprobe',
            '-v', 'error',  # –¢–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏
            '-show_entries', 'stream=codec_type',
            '-of', 'json',
            str(file_path)
        ], capture_output=True, text=True, timeout=10)
        
        if result.returncode != 0:
            raise ValueError("–§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç")
        
        probe_data = json.loads(result.stdout)
        streams = probe_data.get('streams', [])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞
        has_audio = any(s.get('codec_type') == 'audio' for s in streams)
        if not has_audio:
            raise ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∞—É–¥–∏–æ –¥–æ—Ä–æ–∂–∫–∏")
            
    except subprocess.TimeoutExpired:
        raise ValueError("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞")
    except json.JSONDecodeError:
        raise ValueError("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞")


def probe_media_file(file_path: Path) -> dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–µ —á–µ—Ä–µ–∑ ffprobe"""
    import subprocess
    
    try:
        result = subprocess.run([
            'ffprobe',
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            '-show_streams',
            str(file_path)
        ], capture_output=True, text=True, check=True, timeout=10)
        
        return json.loads(result.stdout)
    except subprocess.TimeoutExpired:
        raise ValueError("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞")
    except Exception as e:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")


async def process_audio_file(
    file_path: Path,
    task_id: str,
    options: dict
):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
    try:
        tasks_status[task_id]["status"] = "processing"
        tasks_status[task_id]["progress"] = 10
        tasks_status[task_id]["message"] = "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏..."
        
        import subprocess
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OGG Opus (–≤—Å–µ–≥–¥–∞, –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        tasks_status[task_id]["progress"] = 20
        tasks_status[task_id]["message"] = "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OGG Opus..."
        
        temp_file = TEMP_DIR / f"{task_id}.ogg"
        
        try:
            subprocess.run([
                'ffmpeg',
                '-i', str(file_path),
                '-vn',  # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ
                '-c:a', 'libopus',
                '-b:a', '48k',
                '-ar', '48000',
                '-ac', '1',  # –ú–æ–Ω–æ - –±—ã—Å—Ç—Ä–µ–µ
                str(temp_file),
                '-y'
            ], check=True, capture_output=True)
        except subprocess.CalledProcessError as e:
            error_msg = e.stderr.decode() if e.stderr else str(e)
            logger.error(f"FFmpeg conversion failed for {task_id}: {error_msg}")
            
            # –£–ø—Ä–æ—â—ë–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if "Could not find codec parameters" in error_msg or "Invalid data" in error_msg:
                raise ValueError(
                    "–§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. "
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π."
                )
            else:
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç.")
        
        audio_to_send = temp_file
        
        tasks_status[task_id]["progress"] = 50
        tasks_status[task_id]["message"] = "–ó–∞–≥—Ä—É–∑–∫–∞ –≤ –æ–±–ª–∞–∫–æ..."
        
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤)
        logger.info(f"Starting async transcription for task {task_id}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º Yandex STT
        # speaker_labeling –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ transcribe_async - –∏—Å–ø–æ–ª—å–∑—É–µ–º Resemblyzer –æ—Ç–¥–µ–ª—å–Ω–æ
        operation_id = stt.transcribe_async(
            str(audio_to_send),
            language=options.get("language", "ru-RU"),
            punctuation=options.get("punctuation", True),
            literature_text=options.get("literature", False),
            auto_upload=True,
            # hints=DEFAULT_HINTS,  # –ù–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ async API
        )
        
        logger.info(f"Task {task_id}: operation_id = {operation_id}")
        
        # –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è - –∑–∞–ø—É—Å–∫–∞–µ–º Resemblyzer –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        speaker_segments = None
        if options.get("speaker_labeling", False):
            tasks_status[task_id]["message"] = "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è + –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤..."
            tasks_status[task_id]["progress"] = 60
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º Resemblyzer –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å Yandex
            async def run_diarization():
                try:
                    logger.info(f"Task {task_id}: starting Resemblyzer diarization")
                    return diarizer.diarize(str(audio_to_send), num_speakers=2)
                except Exception as e:
                    logger.error(f"Task {task_id}: diarization failed: {e}")
                    return None
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            diarization_task = asyncio.create_task(run_diarization())
            
            # –ñ–¥—ë–º Yandex
            tasks_status[task_id]["progress"] = 70
            result = stt.wait_for_completion(operation_id, timeout=7200, poll_interval=5)
            
            # –ñ–¥—ë–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é
            tasks_status[task_id]["message"] = "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤..."
            tasks_status[task_id]["progress"] = 75
            speaker_segments = await diarization_task
            
        else:
            # –ë–µ–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ - –ø—Ä–æ—Å—Ç–æ –∂–¥—ë–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            tasks_status[task_id]["message"] = "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (–æ–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞)..."
            tasks_status[task_id]["progress"] = 60
            result = stt.wait_for_completion(operation_id, timeout=7200, poll_interval=5)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑ Object Storage
        try:
            object_name = Path(audio_to_send).name
            stt.delete_from_storage(object_name)
            logger.info(f"Task {task_id}: cleaned up S3 file {object_name}")
        except Exception as e:
            logger.warning(f"Task {task_id}: failed to cleanup S3 file: {e}")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if speaker_segments:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å–æ —Å–ø–∏–∫–µ—Ä–∞–º–∏
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –∏–∑ chunks Yandex
                all_words = []
                for chunk in result.get('chunks', []):
                    for alt in chunk.get('alternatives', []):
                        all_words.extend(alt.get('words', []))
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π
                words_with_speakers = merge_transcription_with_speakers(all_words, speaker_segments)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ –¥–∏–∞–ª–æ–≥
                text = format_speakers_dialogue(words_with_speakers)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º enriched data
                result['words_with_speakers'] = words_with_speakers
                result['speaker_segments'] = speaker_segments
                
                logger.info(f"Task {task_id}: merged {len(words_with_speakers)} words with {len(set(s['speaker'] for s in speaker_segments))} speakers")
            except Exception as e:
                logger.error(f"Task {task_id}: failed to merge speakers: {e}")
                text = result.get('result', '')
        else:
            text = result.get('result', '')
        
        # –û—á–∏—Å—Ç–∫–∞ –∏–∑ S3
        try:
            object_name = Path(audio_to_send).name
            stt.delete_from_storage(object_name)
            logger.info(f"Task {task_id}: cleaned up S3 object {object_name}")
        except Exception as e:
            logger.warning(f"Task {task_id}: failed to delete from S3: {e}")
        
        tasks_status[task_id]["progress"] = 70
        
        # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (–∑–≤—É–∫–∏ + –ø–∞—Ä–∞–∑–∏—Ç—ã + –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)
        if options.get("clean", False) or options.get("corrections", True):
            tasks_status[task_id]["message"] = "–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞..."
            text = cleaner.clean(
                text,
                remove_filler_sounds=True,  # –í—Å–µ–≥–¥–∞ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∑–≤—É–∫–∏ (—ç—ç—ç, –º–º–º, –±–µ, –º–µ)
                remove_filler_words=options.get("clean", False),  # –°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã (–ø–æ –∑–∞–ø—Ä–æ—Å—É)
                fix_artifacts=options.get("corrections", True),  # –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã (–∏–∏—à–∫–∞ ‚Üí –ò–ò—à–∫–∞)
            )
        
        tasks_status[task_id]["progress"] = 90
        
        # JTBD –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        jtbd_result = None
        if options.get("analyze_jtbd", True) and jtbd_analyzer:
            try:
                tasks_status[task_id]["message"] = "JTBD –∞–Ω–∞–ª–∏–∑..."
                tasks_status[task_id]["progress"] = 92
                
                logger.info(f"Task {task_id}: starting JTBD analysis")
                jtbd_result = jtbd_analyzer.analyze(text)
                
                logger.info(
                    f"Task {task_id}: JTBD analysis completed, "
                    f"{jtbd_result['metadata']['total_elements']} elements found"
                )
            except Exception as e:
                logger.error(f"Task {task_id}: JTBD analysis failed: {e}")
                jtbd_result = {
                    "error": str(e),
                    "jobs": [], "pains": [], "gains": [], "context": [], "triggers": [],
                    "summary": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
                }
        
        tasks_status[task_id]["progress"] = 95
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result_file = RESULTS_DIR / f"{task_id}.json"
        result_data = {
            "task_id": task_id,
            "text": text,
            "original_filename": tasks_status[task_id]["filename"],
            "timestamp": datetime.now().isoformat(),
            "options": options,
            "raw_result": result,
            "jtbd": jtbd_result,
        }
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if audio_to_send != file_path:
            audio_to_send.unlink(missing_ok=True)
        
        tasks_status[task_id]["status"] = "completed"
        tasks_status[task_id]["progress"] = 100
        tasks_status[task_id]["result"] = text
        tasks_status[task_id]["result_file"] = str(result_file)
        
    except Exception as e:
        error_msg = str(e)
        error_trace = tb.format_exc()
        
        logger.error(f"Task {task_id} failed: {error_msg}")
        logger.debug(f"Task {task_id} traceback:\n{error_trace}")
        
        tasks_status[task_id]["status"] = "failed"
        tasks_status[task_id]["error"] = error_msg
        tasks_status[task_id]["traceback"] = error_trace


async def worker():
    """–í–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏"""
    while True:
        task = await task_queue.get()
        await process_audio_file(
            task["file_path"],
            task["task_id"],
            task["options"]
        )
        task_queue.task_done()


@app.on_event("startup")
async def startup_event():
    """–ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–æ–≤ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    # 3 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–∞
    for _ in range(3):
        asyncio.create_task(worker())


@app.get("/favicon.ico")
async def favicon():
    """Favicon –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–∞"""
    favicon_path = Path(__file__).parent / "static" / "favicon.ico"
    if favicon_path.exists():
        return FileResponse(favicon_path, media_type="image/x-icon")
    return JSONResponse(status_code=404, content={"detail": "Favicon not found"})


@app.get("/", response_class=HTMLResponse)
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    html_path = Path(__file__).parent / "static" / "index.html"
    if html_path.exists():
        return html_path.read_text(encoding='utf-8')
    
    # –ü—Ä–æ—Å—Ç–µ–π—à–∏–π HTML –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>HearYou STT Service</title>
        <meta charset="utf-8">
    </head>
    <body>
        <h1>HearYou STT Service</h1>
        <p>API —Ä–∞–±–æ—Ç–∞–µ—Ç! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /docs –¥–ª—è Swagger UI</p>
    </body>
    </html>
    """


@app.post("/upload-chunk")
async def upload_chunk(
    upload_id: str = Form(...),
    chunk_index: int = Form(...),
    total_chunks: int = Form(...),
    filename: str = Form(...),
    chunk: UploadFile = File(...),
    x_forwarded_for: str = Header(None, alias="X-Forwarded-For"),
    x_real_ip: str = Header(None, alias="X-Real-IP")
):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ —á–∞—Å—Ç—è–º (chunked upload)
    
    - **upload_id**: —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∑–∞–≥—Ä—É–∑–∫–∏
    - **chunk_index**: –Ω–æ–º–µ—Ä —á–∞—Å—Ç–∏ (0-based)
    - **total_chunks**: –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π
    - **filename**: –∏–º—è —Ñ–∞–π–ª–∞
    - **chunk**: –¥–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–∏
    """
    
    # Rate limiting
    client_ip = x_forwarded_for or x_real_ip or "direct"
    if client_ip and ',' in client_ip:
        client_ip = client_ip.split(',')[0].strip()
    
    logger.info(f"Chunk upload from {client_ip}: {upload_id} [{chunk_index+1}/{total_chunks}]")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è upload –µ—Å–ª–∏ –ø–µ—Ä–≤—ã–π —á–∞–Ω–∫
    if upload_id not in chunked_uploads:
        safe_filename = sanitize_filename(filename)
        chunked_uploads[upload_id] = {
            "filename": safe_filename,
            "total_chunks": total_chunks,
            "received_chunks": set(),
            "chunk_dir": CHUNKS_DIR / upload_id,
            "started_at": datetime.now().isoformat()
        }
        chunked_uploads[upload_id]["chunk_dir"].mkdir(exist_ok=True)
        logger.info(f"Started chunked upload: {upload_id} for {safe_filename}")
    
    upload_info = chunked_uploads[upload_id]
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–∞
    chunk_path = upload_info["chunk_dir"] / f"chunk_{chunk_index}"
    with open(chunk_path, "wb") as f:
        shutil.copyfileobj(chunk.file, f)
    
    upload_info["received_chunks"].add(chunk_index)
    received_count = len(upload_info["received_chunks"])
    
    logger.debug(f"Chunk {chunk_index} saved, progress: {received_count}/{total_chunks}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    is_complete = received_count == total_chunks
    
    return {
        "upload_id": upload_id,
        "chunk_index": chunk_index,
        "received": received_count,
        "total": total_chunks,
        "complete": is_complete,
        "progress": round((received_count / total_chunks) * 100, 1)
    }


@app.post("/complete-upload")
async def complete_upload(
    upload_id: str = Form(...),
    language: str = Form("ru-RU"),
    punctuation: bool = Form(True),
    literature: bool = Form(False),
    clean: bool = Form(False),
    corrections: bool = Form(True),
    analyze_jtbd: bool = Form(False)  # JTBD –æ—Ç–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
):
    """
    –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ chunked upload –∏ –∑–∞–ø—É—Å–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    """
    
    if upload_id not in chunked_uploads:
        raise HTTPException(status_code=404, detail="Upload ID not found")
    
    upload_info = chunked_uploads[upload_id]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –≤—Å–µ —á–∞–Ω–∫–∏ –ø–æ–ª—É—á–µ–Ω—ã
    if len(upload_info["received_chunks"]) != upload_info["total_chunks"]:
        raise HTTPException(
            status_code=400, 
            detail=f"Incomplete upload: {len(upload_info['received_chunks'])}/{upload_info['total_chunks']} chunks"
        )
    
    logger.info(f"Assembling chunked upload: {upload_id}")
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤
    task_id = hashlib.md5(f"{upload_id}{datetime.now().isoformat()}".encode()).hexdigest()[:16]
    final_path = UPLOAD_DIR / f"{task_id}_{upload_info['filename']}"
    
    with open(final_path, "wb") as final_file:
        for i in range(upload_info["total_chunks"]):
            chunk_path = upload_info["chunk_dir"] / f"chunk_{i}"
            with open(chunk_path, "rb") as chunk_file:
                shutil.copyfileobj(chunk_file, final_file)
    
    logger.info(f"Assembled file: {final_path}, size: {final_path.stat().st_size}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
    if final_path.stat().st_size > MAX_FILE_SIZE:
        final_path.unlink()
        raise HTTPException(
            status_code=413,
            detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {final_path.stat().st_size // (1024*1024)} –ú–ë"
        )
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
    try:
        validate_file_security(upload_info['filename'], final_path)
    except ValueError as e:
        final_path.unlink()
        raise HTTPException(status_code=400, detail=str(e))
    
    # –û—á–∏—Å—Ç–∫–∞ —á–∞–Ω–∫–æ–≤
    shutil.rmtree(upload_info["chunk_dir"], ignore_errors=True)
    del chunked_uploads[upload_id]
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
    safe_language = sanitize_language_code(language)
    
    options = {
        "language": safe_language,
        "punctuation": punctuation,
        "literature": literature,
        "clean": clean,
        "corrections": corrections,
        "analyze_jtbd": analyze_jtbd,
    }
    
    tasks_status[task_id] = {
        "status": "queued",
        "progress": 0,
        "filename": upload_info["filename"],
        "created_at": datetime.now().isoformat(),
        "user": "chunked_upload",
    }
    
    await task_queue.put({
        "file_path": final_path,
        "task_id": task_id,
        "options": options,
    })
    
    logger.info(f"Chunked upload completed and queued: {task_id}")
    
    return {
        "task_id": task_id,
        "status": "queued",
        "message": "–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å"
    }


@app.post("/test-upload")
async def test_upload(file: UploadFile = File(...)):
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç - –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª"""
    logger.info(f"üß™ TEST: Received file={file.filename}, size={file.size}, content_type={file.content_type}")
    return {"status": "ok", "filename": file.filename, "content_type": file.content_type}

@app.post("/transcribe")
async def transcribe(
    file: UploadFile = File(...),
    language: str = Form("ru-RU"),
    punctuation: bool = Form(True),
    literature: bool = Form(False),
    clean: bool = Form(False),
    corrections: bool = Form(True),
    speaker_labeling: bool = Form(False),
    analyze_jtbd: bool = Form(False),  # JTBD –æ—Ç–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    user: str = Header(None, alias="X-User"),
    x_forwarded_for: str = Header(None, alias="X-Forwarded-For"),
    x_real_ip: str = Header(None, alias="X-Real-IP")
):
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
    
    - **file**: –∞—É–¥–∏–æ —Ñ–∞–π–ª (MP3, WAV, AAC, OGG –∏ —Ç.–¥.)
    - **language**: —è–∑—ã–∫ (ru-RU, en-US, etc.)
    - **speaker_labeling**: –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Å–ø–∏–∫–µ—Ä–æ–≤ (–∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç)
    - **punctuation**: —Ä–∞—Å—Å—Ç–∞–≤–ª—è—Ç—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    - **literature**: –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç (Yandex —Ñ–∏–ª—å—Ç—Ä)
    - **clean**: —É–±—Ä–∞—Ç—å —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã
    - **corrections**: –ø—Ä–∏–º–µ–Ω—è—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    - **analyze_jtbd**: –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ JTBD —Ñ—Ä–µ–π–º–≤–æ—Ä–∫—É (Jobs To Be Done)
    """
    
    # üîç STEP 1: –ü–æ–ª—É—á–∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    logger.info(f"üì• STEP 1: Received params - file={file.filename}, language={language}, punctuation={punctuation}, literature={literature}, clean={clean}, corrections={corrections}, speaker_labeling={speaker_labeling}, analyze_jtbd={analyze_jtbd}")
    
    # Rate limiting (–∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ø–∞–º–∞)
    # –ü–æ–ª—É—á–∞–µ–º IP –∏–∑ headers (–µ—Å–ª–∏ –∑–∞ –ø—Ä–æ–∫—Å–∏) –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
    client_ip = x_forwarded_for or x_real_ip or "direct"
    logger.info(f"üìç STEP 2: Client IP = {client_ip}")
    if client_ip and ',' in client_ip:
        client_ip = client_ip.split(',')[0].strip()  # –ü–µ—Ä–≤—ã–π IP –∏–∑ —Å–ø–∏—Å–∫–∞
    
    logger.info(f"Upload request from {client_ip}: {file.filename} ({file.content_type})")
    
    logger.info("‚è±Ô∏è STEP 3: Checking rate limit...")
    try:
        check_rate_limit(client_ip)
        logger.info("‚úÖ STEP 3: Rate limit OK")
    except HTTPException as e:
        logger.warning(f"‚ùå STEP 3: Rate limit exceeded for {client_ip}")
        raise
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è task_id
    logger.info("üîë STEP 4: Generating task_id...")
    task_id = hashlib.md5(
        f"{file.filename}{datetime.now().isoformat()}".encode()
    ).hexdigest()[:16]
    logger.info(f"‚úÖ STEP 4: task_id = {task_id}")
    
    # –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–∑–∞—â–∏—Ç–∞ –æ—Ç –∏–Ω—ä–µ–∫—Ü–∏–π)
    logger.info("üßπ STEP 5: Sanitizing filename...")
    safe_filename = sanitize_filename(file.filename)
    if file.filename != safe_filename:
        logger.info(f"‚ö†Ô∏è  Sanitized filename: '{file.filename}' -> '{safe_filename}'")
    logger.info(f"‚úÖ STEP 5: safe_filename = {safe_filename}")
    
    # –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è —è–∑—ã–∫–æ–≤–æ–≥–æ –∫–æ–¥–∞
    logger.info("üåç STEP 6: Sanitizing language code...")
    safe_language = sanitize_language_code(language)
    logger.info(f"‚úÖ STEP 6: safe_language = {safe_language}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
    logger.info("üìè STEP 7: Checking file size...")
    file.file.seek(0, 2)  # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å—Å—è –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
    file_size = file.file.tell()
    file.file.seek(0)  # –í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –Ω–∞—á–∞–ª–æ
    logger.info(f"‚úÖ STEP 7: file_size = {file_size} bytes ({file_size / (1024*1024):.2f} MB)")
    
    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE // (1024*1024)} –ú–ë, –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {file_size // (1024*1024)} –ú–ë"
        )
    
    if file_size == 0:
        logger.error("‚ùå STEP 7: File is empty")
        raise HTTPException(status_code=400, detail="–§–∞–π–ª –ø—É—Å—Ç–æ–π")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    logger.info(f"üíæ STEP 8: Saving file to {UPLOAD_DIR}...")
    file_path = UPLOAD_DIR / f"{task_id}_{safe_filename}"
    try:
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        logger.info(f"‚úÖ STEP 8: File saved to {file_path}")
    except Exception as e:
        logger.error(f"‚ùå STEP 8: Failed to save file: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–∞
    logger.info(f"üîí STEP 9: Validating file security...")
    try:
        validate_file_security(safe_filename, file_path)
        logger.info(f"‚úÖ STEP 9: File validated successfully: {safe_filename}")
    except ValueError as e:
        # –£–¥–∞–ª—è–µ–º –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–∞–π–ª
        logger.error(f"‚ùå STEP 9: File validation failed: {safe_filename}, reason: {e}")
        file_path.unlink(missing_ok=True)
        raise HTTPException(status_code=400, detail=str(e))
    
    # –û–ø—Ü–∏–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —è–∑—ã–∫)
    logger.info("‚öôÔ∏è STEP 10: Creating options...")
    options = {
        "language": safe_language,
        "punctuation": punctuation,
        "literature": literature,
        "clean": clean,
        "corrections": corrections,
        "speaker_labeling": speaker_labeling,
        "analyze_jtbd": analyze_jtbd,
    }
    logger.info(f"‚úÖ STEP 10: options = {options}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è)
    logger.info("üìã STEP 11: Creating task status...")
    tasks_status[task_id] = {
        "status": "queued",
        "progress": 0,
        "filename": safe_filename,  # –°–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        "created_at": datetime.now().isoformat(),
        "user": user or "anonymous",
    }
    logger.info(f"‚úÖ STEP 11: Task status created for {task_id}")
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –æ—á–µ—Ä–µ–¥—å
    logger.info("üì§ STEP 12: Adding task to queue...")
    await task_queue.put({
        "file_path": file_path,
        "task_id": task_id,
        "options": options,
    })
    logger.info(f"‚úÖ STEP 12: Task {task_id} added to queue")
    
    return {
        "task_id": task_id,
        "status": "queued",
        "message": "–ó–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å"
    }


@app.get("/status/{task_id}")
async def get_status(task_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏"""
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail="Task not found")
    
    return tasks_status[task_id]



@app.get("/status/{task_id}/stream")
async def stream_status(task_id: str):
    """SSE endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Å—Ç–∞—Ç—É—Å–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    async def event_generator():
        while True:
            if task_id not in tasks_status:
                yield f"data: {{\"error\": \"Task not found\"}}\n\n"
                break
            
            task = tasks_status[task_id]
            
            data = {
                "status": task["status"],
                "progress": task.get("progress", 0),
                "message": task.get("message", ""),
                "filename": task.get("filename", "")
            }
            
            if task["status"] == "completed":
                if task.get("result"):
                    data["result"] = task["result"]
                elif task.get("result_file"):
                    result_path = RESULTS_DIR / f"{task_id}.json"
                    if result_path.exists():
                        with open(result_path, "r", encoding="utf-8") as f:
                            result_data = json.load(f)
                            data["result"] = result_data.get("text", "")
            
            yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
            
            if task["status"] in ["completed", "failed", "error"]:
                break
            
            await asyncio.sleep(1)
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")


@app.get("/result/{task_id}")
async def get_result(task_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏"""
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫–µ (persists across restarts)
    result_file = RESULTS_DIR / f"{task_id}.json"
    
    if result_file.exists():
        # –§–∞–π–ª –µ—Å—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        with open(result_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    # –§–∞–π–ª–∞ –Ω–µ—Ç - –ø—Ä–æ–≤–µ—Ä—è–µ–º in-memory —Å—Ç–∞—Ç—É—Å
    if task_id not in tasks_status:
        raise HTTPException(
            status_code=404, 
            detail="–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–æ–∑–º–æ–∂–Ω–æ —Ñ–∞–π–ª –±—ã–ª —É–¥–∞–ª—ë–Ω –∏–ª–∏ —Å—Ä–æ–∫ —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç—ë–∫."
        )
    
    status = tasks_status[task_id]
    
    if status["status"] == "failed":
        raise HTTPException(
            status_code=400,
            detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {status.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
        )
    
    if status["status"] != "completed":
        raise HTTPException(
            status_code=400,
            detail=f"–ó–∞–¥–∞—á–∞ –µ—â—ë –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è. –°—Ç–∞—Ç—É—Å: {status['status']}"
        )
    
    # –°—Ç–∞—Ç—É—Å completed, –Ω–æ —Ñ–∞–π–ª–∞ –Ω–µ—Ç
    raise HTTPException(
        status_code=404, 
        detail="–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –±—ã–ª —É–¥–∞–ª—ë–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª –∑–∞–Ω–æ–≤–æ."
    )


@app.get("/download/{task_id}")
async def download_result(task_id: str):
    """–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª"""
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫–µ
    result_file = RESULTS_DIR / f"{task_id}.json"
    
    if not result_file.exists():
        raise HTTPException(
            status_code=404, 
            detail="–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–æ–∑–º–æ–∂–Ω–æ —Ñ–∞–π–ª –±—ã–ª —É–¥–∞–ª—ë–Ω –∏–ª–∏ —Å—Ä–æ–∫ —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç—ë–∫."
        )
    
    with open(result_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # –°–æ–∑–¥–∞—Ç—å TXT —Ñ–∞–π–ª
    txt_file = TEMP_DIR / f"{task_id}.txt"
    txt_file.write_text(data["text"], encoding='utf-8')
    
    # –ò–º—è —Ñ–∞–π–ª–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ –∏–∑ in-memory —Å—Ç–∞—Ç—É—Å–∞
    filename = data.get("original_filename", "transcript.txt")
    if not filename.endswith('.txt'):
        filename = filename.rsplit('.', 1)[0] + '.txt'
    
    return FileResponse(
        txt_file,
        media_type='text/plain',
        filename=filename
    )


@app.get("/history")
async def get_history(limit: int = 50):
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π"""
    history = []
    
    for task_id, status in sorted(
        tasks_status.items(),
        key=lambda x: x[1].get("created_at", ""),
        reverse=True
    )[:limit]:
        history.append({
            "task_id": task_id,
            "filename": status.get("filename"),
            "status": status.get("status"),
            "created_at": status.get("created_at"),
            "user": status.get("user", "anonymous"),
        })
    
    return history


@app.get("/stats")
async def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Ä–≤–∏—Å–∞"""
    total = len(tasks_status)
    completed = sum(1 for s in tasks_status.values() if s["status"] == "completed")
    failed = sum(1 for s in tasks_status.values() if s["status"] == "failed")
    queued = sum(1 for s in tasks_status.values() if s["status"] == "queued")
    processing = sum(1 for s in tasks_status.values() if s["status"] == "processing")
    
    return {
        "total_tasks": total,
        "completed": completed,
        "failed": failed,
        "queued": queued,
        "processing": processing,
        "queue_size": task_queue.qsize(),
    }


@app.get("/formats")
async def get_supported_formats():
    """–°–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    return {
        "supported": "–õ—é–±—ã–µ —Ñ–∞–π–ª—ã —Å –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–æ–º",
        "max_file_size_mb": MAX_FILE_SIZE // (1024 * 1024),
        "validation": "ffprobe –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞",
        "note": "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–Ω–∏–º–∞–µ—Ç FFmpeg (–ª—é–±—ã–µ –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ). –ò–∑ –≤–∏–¥–µ–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∞—É–¥–∏–æ.",
        "examples": "MP3, WAV, AAC, M4A, OGG, FLAC, MP4, MKV, AVI, WebM, –∏ —Å–æ—Ç–Ω–∏ –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"
    }


@app.get("/logs")
async def get_logs(lines: int = 100):
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–æ–≤
    - **lines**: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç—Ä–æ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100, –º–∞–∫—Å 1000)
    """
    lines = min(lines, 1000)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
    
    log_file = LOGS_DIR / "app.log"
    if not log_file.exists():
        return {"logs": [], "message": "–õ–æ–≥–∏ –ø–æ–∫–∞ –ø—É—Å—Ç—ã"}
    
    try:
        # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å—Ç—Ä–æ–∫
        with open(log_file, 'r', encoding='utf-8') as f:
            all_lines = f.readlines()
            last_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
        
        return {
            "logs": [line.strip() for line in last_lines],
            "total_lines": len(all_lines),
            "showing": len(last_lines)
        }
    except Exception as e:
        logger.error(f"Failed to read logs: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–≥–æ–≤: {e}")


@app.delete("/cleanup")
async def cleanup_old_files(days: int = 7):
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    import time
    
    cutoff = time.time() - (days * 86400)
    cleaned = 0
    
    for dir in [UPLOAD_DIR, RESULTS_DIR, TEMP_DIR]:
        for file in dir.iterdir():
            if file.stat().st_mtime < cutoff:
                file.unlink()
                cleaned += 1
    
    return {"cleaned_files": cleaned}


if __name__ == "__main__":
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
